{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re \n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"User-Agent\" : \"Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Mobile Safari/537.36\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = \"https://www.amazon.com.br/Cadeira-Escrit%C3%B3rio-Secret%C3%A1ria-Cromada-Rodinha/product-reviews/B0BWSJY84N/ref=cm_cr_getr_mb_paging_btm_4?ie=UTF8&reviewerType=all_reviews&pageNumber=4\"\n",
    "requisicao = requests.get(link , headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [503]>\n",
      "<!doctype html><html><head><meta charset=\"utf-8\"><meta http-equiv=\"x-ua-compatible\" content=\"ie=edge\"><meta name=\"viewport\" content=\"width=device-width, initial-scale=1, shrink-to-fit=no\"><title>Amazon.com.br Algo deu errado</title><style>html,body{padding:0;margin:0}img{border:0}#a,#b{background:#232f3e;padding:11px;height:35px}#c{position:absolute;left:22px;top:12px}#e{position:relative;max-width:800px;padding:0 40px 0 171px}#f,#g{height:35px;border:0;font-size:1em}#f{width:100%;margin:0;padding:0 10px;border-radius:4px 0 0 4px}#g{cursor:pointer;background:#febd69;font-weight:bold;border-radius:0 4px 4px 0;-webkit-appearance:none;position:absolute;top:0;right:0;padding:0 12px}@media(max-width:500px){#e{padding-left:0}#b{padding:55px 10px 10px}#c{left:6px}}#h{text-align:center;margin:30px 0}#h img{max-width:90%}#d{display:none}#d[src]{display:inline}</style></head><body><form id=\"b\" accept-charset=\"utf-8\" action=\"/s\" method=\"GET\" role=\"search\"><a href=\"/\"><img id=\"c\" src=\"https://images-na.ssl-images-amazon.com/images/G/32/error/logo._TTD_.png\" alt=\"Amazon.com.br\"></a><div id=\"e\"><input id=\"f\" name=\"field-keywords\" placeholder=\"Buscar\"><input id=\"g\" type=\"submit\" value=\"Ir\"></div></form><div id=\"h\"><div><a href=\"/\"><img src=\"https://images-na.ssl-images-amazon.com/images/G/32/error/500-title._TTD_.png\" alt=\"Desculpe! Algo deu errado. Tente novamente ou volte para a p√É¬°gina inicial da Amazon.\"></a></div><img id=\"d\" alt=\"Cachorros da Amazon\"><script>document.getElementById(\"d\").src=\"https://images-na.ssl-images-amazon.com/images/G/32/error/\"+(Math.floor(Math.random()*200)+1)+\"._TTD_.jpg\";</script></div></body></html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(requisicao)\n",
    "print(requisicao.text)  # Verifica se a resposta √© 200 (tudo certo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <meta content=\"ie=edge\" http-equiv=\"x-ua-compatible\"/>\n",
      "  <meta content=\"width=device-width, initial-scale=1, shrink-to-fit=no\" name=\"viewport\"/>\n",
      "  <title>\n",
      "   Amazon.com.br Algo deu errado\n",
      "  </title>\n",
      "  <style>\n",
      "   html,body{padding:0;margin:0}img{border:0}#a,#b{background:#232f3e;padding:11px;height:35px}#c{position:absolute;left:22px;top:12px}#e{position:relative;max-width:800px;padding:0 40px 0 171px}#f,#g{height:35px;border:0;font-size:1em}#f{width:100%;margin:0;padding:0 10px;border-radius:4px 0 0 4px}#g{cursor:pointer;background:#febd69;font-weight:bold;border-radius:0 4px 4px 0;-webkit-appearance:none;position:absolute;top:0;right:0;padding:0 12px}@media(max-width:500px){#e{padding-left:0}#b{padding:55px 10px 10px}#c{left:6px}}#h{text-align:center;margin:30px 0}#h img{max-width:90%}#d{display:none}#d[src]{display:inline}\n",
      "  </style>\n",
      " </head>\n",
      " <body>\n",
      "  <form accept-charset=\"utf-8\" action=\"/s\" id=\"b\" method=\"GET\" role=\"search\">\n",
      "   <a href=\"/\">\n",
      "    <img alt=\"Amazon.com.br\" id=\"c\" src=\"https://images-na.ssl-images-amazon.com/images/G/32/error/logo._TTD_.png\"/>\n",
      "   </a>\n",
      "   <div id=\"e\">\n",
      "    <input id=\"f\" name=\"field-keywords\" placeholder=\"Buscar\"/>\n",
      "    <input id=\"g\" type=\"submit\" value=\"Ir\"/>\n",
      "   </div>\n",
      "  </form>\n",
      "  <div id=\"h\">\n",
      "   <div>\n",
      "    <a href=\"/\">\n",
      "     <img alt=\"Desculpe! Algo deu errado. Tente novamente ou volte para a p√É¬°gina inicial da Amazon.\" src=\"https://images-na.ssl-images-amazon.com/images/G/32/error/500-title._TTD_.png\"/>\n",
      "    </a>\n",
      "   </div>\n",
      "   <img alt=\"Cachorros da Amazon\" id=\"d\"/>\n",
      "   <script>\n",
      "    document.getElementById(\"d\").src=\"https://images-na.ssl-images-amazon.com/images/G/32/error/\"+(Math.floor(Math.random()*200)+1)+\"._TTD_.jpg\";\n",
      "   </script>\n",
      "  </div>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "site = BeautifulSoup(requisicao.text, \"html.parser\")\n",
    "print(site.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Amazon.com.br Algo deu errado</title>\n"
     ]
    }
   ],
   "source": [
    "titulo = site.find('title')  # Primeiro elemento 'title' encontrado\n",
    "print(titulo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A m√≠dia n√£o p√¥de ser carregada.\n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "Boa, N√£o √© dificil de montar, mas exige um pouco de for√ßa pra ajustar nos pinos de encaixe. Encaixou bem em minhas costas, porem pela curvatura o assento torna-se pequeno, principalmente se for para pessoas maiores de 1.60 de altura. No mais recomendo, √© boa, as rodinhas giram bem e o assento √© macio.\n",
      "A base veio um pouco riscada, nada demais. Dif√≠cil montar sozinha na hora de encaixar os bra√ßos no assento. Fora isso, adorei a compra\n",
      "Muito boa a cadeira.\n",
      "muito boa\n",
      "Bom o produto recomendo\n",
      "Sentar nessa cadeira causa a impress√£o de que ela est√° te jogando para frente. Se eu quiser ficar numa posi√ß√£o confort√°vel com ela, tenho que ficar exercendo uma for√ßa contra o encosto para conseguir ficar ereto.A alavanca embaixo me enganou. Achei que fosse para regular a altura mas √© apenas para ejetar o assento da base.Para quem usava um banquinho para a escrivaninha, essa cadeira com certeza foi um upgrade, e, infelizmente, nessa faixa de pre√ßo n√£o h√° muitas op√ß√µes melhores do que esta.\n",
      "Apenas 6 meses de uso e terei que comprar outra cadeira. A cadeira √© fr√°gil, apenas uma pessoa de 80kg usando, para trabalhar em home office duas ou tr√™s vezes na semana e ela quebrou e n√£o tem como consertar. A pe√ßa que sustenta o assento quebrou por dentro. A cadeira tamb√©m n√£o √© confort√°vel.\n",
      "N√£o gostei do acabamento do produto. O estofado n√£o √© legal, quase sem espuma e acredito que n√£o durar√° muito. Grita fragilidade. Na montagem as pe√ßas precisam ser encaixadas com certa for√ßa para ficarem perfeitas. O encosto √© bom e fresco. Detalhes das rodas em branco, diferente do que aparece nas fotos, achei estranho. N√£o recomendo.\n",
      "A qualidade do produto √© proporcional ao pre√ßo ofertado. N√£o aconselho para pessoas altas (+ 1,75) pois se torna muito desconfort√°vel. Um ponto importante √© que a transportadora que a empresa realiza a venda do produto √© p√©ssima. Minha cadeira chegou extremamente danificada e est√° sendo uma dor de cabe√ßa solicitar a devolu√ß√£o.\n",
      "Otimo custo beneficio\n"
     ]
    }
   ],
   "source": [
    "def __get_reviews(url):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',\n",
    "        'Accept-Language': 'en-US,en;q=0.5',\n",
    "        'Accept-Encoding': 'gzip, deflate, br',\n",
    "        'Connection': 'keep-alive',\n",
    "        'Upgrade-Insecure-Requests': '1',\n",
    "        'DNT': '1'\n",
    "    }\n",
    "    \n",
    "    # Tentar at√© 5 vezes com um atraso de 5 segundos entre as tentativas\n",
    "    for _ in range(5):\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            break\n",
    "        else:\n",
    "            print(f\"Falha ao recuperar a p√°gina da web. C√≥digo de status: {response.status_code}. Tentando novamente...\")\n",
    "            time.sleep(5)\n",
    "    else:\n",
    "        print(\"Falha ao recuperar a p√°gina da web ap√≥s v√°rias tentativas.\")\n",
    "        return []\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    reviews = []\n",
    "\n",
    "    for review in soup.find_all(\"span\", {\"data-hook\": \"review-body\"}):\n",
    "        reviews.append(review.get_text().strip())\n",
    "\n",
    "    return reviews\n",
    "\n",
    "# Exemplo de uso\n",
    "url = \"https://www.amazon.com.br/Cadeira-Escrit%C3%B3rio-Secret%C3%A1ria-Cromada-Rodinha/product-reviews/B0BWSJY84N/ref=cm_cr_getr_mb_paging_btm_4?ie=UTF8&reviewerType=all_reviews&pageNumber=4\"\n",
    "reviews = __get_reviews(url)\n",
    "for review in reviews:\n",
    "    print(review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A m√≠dia n√£o p√¥de ser carregada.\\n                \\n\\n\\n\\nBoa, N√£o √© dificil de montar, mas exige um pouco de for√ßa pra ajustar nos pinos de encaixe. Encaixou bem em minhas costas, porem pela curvatura o assento torna-se pequeno, principalmente se for para pessoas maiores de 1.60 de altura. No mais recomendo, √© boa, as rodinhas giram bem e o assento √© macio.',\n",
       " 'A base veio um pouco riscada, nada demais. Dif√≠cil montar sozinha na hora de encaixar os bra√ßos no assento. Fora isso, adorei a compra',\n",
       " 'Muito boa a cadeira.',\n",
       " 'muito boa',\n",
       " 'Bom o produto recomendo',\n",
       " 'Sentar nessa cadeira causa a impress√£o de que ela est√° te jogando para frente. Se eu quiser ficar numa posi√ß√£o confort√°vel com ela, tenho que ficar exercendo uma for√ßa contra o encosto para conseguir ficar ereto.A alavanca embaixo me enganou. Achei que fosse para regular a altura mas √© apenas para ejetar o assento da base.Para quem usava um banquinho para a escrivaninha, essa cadeira com certeza foi um upgrade, e, infelizmente, nessa faixa de pre√ßo n√£o h√° muitas op√ß√µes melhores do que esta.',\n",
       " 'Apenas 6 meses de uso e terei que comprar outra cadeira. A cadeira √© fr√°gil, apenas uma pessoa de 80kg usando, para trabalhar em home office duas ou tr√™s vezes na semana e ela quebrou e n√£o tem como consertar. A pe√ßa que sustenta o assento quebrou por dentro. A cadeira tamb√©m n√£o √© confort√°vel.',\n",
       " 'N√£o gostei do acabamento do produto. O estofado n√£o √© legal, quase sem espuma e acredito que n√£o durar√° muito. Grita fragilidade. Na montagem as pe√ßas precisam ser encaixadas com certa for√ßa para ficarem perfeitas. O encosto √© bom e fresco. Detalhes das rodas em branco, diferente do que aparece nas fotos, achei estranho. N√£o recomendo.',\n",
       " 'A qualidade do produto √© proporcional ao pre√ßo ofertado. N√£o aconselho para pessoas altas (+ 1,75) pois se torna muito desconfort√°vel. Um ponto importante √© que a transportadora que a empresa realiza a venda do produto √© p√©ssima. Minha cadeira chegou extremamente danificada e est√° sendo uma dor de cabe√ßa solicitar a devolu√ß√£o.',\n",
       " 'Otimo custo beneficio']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             content\n",
      "0  A m√≠dia n√£o p√¥de ser carregada.\\n             ...\n",
      "1  A base veio um pouco riscada, nada demais. Dif...\n",
      "2                               Muito boa a cadeira.\n",
      "3                                          muito boa\n",
      "4                            Bom o produto recomendo\n",
      "5  Sentar nessa cadeira causa a impress√£o de que ...\n",
      "6  Apenas 6 meses de uso e terei que comprar outr...\n",
      "7  N√£o gostei do acabamento do produto. O estofad...\n",
      "8  A qualidade do produto √© proporcional ao pre√ßo...\n",
      "9                              Otimo custo beneficio\n"
     ]
    }
   ],
   "source": [
    "base = pd.DataFrame(reviews, columns=['content'])\n",
    "print(base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, '√©': 2, 'de': 3, 'n√£o': 4, 'para': 5, 'que': 6, 'o': 7, 'e': 8, 'cadeira': 9, 'do': 10, 'um': 11, 'assento': 12, 'boa': 13, 'se': 14, 'muito': 15, 'produto': 16, 'for√ßa': 17, 'em': 18, 'recomendo': 19, 'na': 20, 'ela': 21, 'ficar': 22, 'com': 23, 'uma': 24, 'apenas': 25, 'ser': 26, 'montar': 27, 'mas': 28, 'pouco': 29, 'bem': 30, 'torna': 31, 'pessoas': 32, '1': 33, 'altura': 34, 'no': 35, 'as': 36, 'base': 37, 'bom': 38, 'nessa': 39, 'est√°': 40, 'confort√°vel': 41, 'encosto': 42, 'achei': 43, 'pre√ßo': 44, 'quebrou': 45, 'm√≠dia': 46, 'p√¥de': 47, 'carregada': 48, 'dificil': 49, 'exige': 50, 'pra': 51, 'ajustar': 52, 'nos': 53, 'pinos': 54, 'encaixe': 55, 'encaixou': 56, 'minhas': 57, 'costas': 58, 'porem': 59, 'pela': 60, 'curvatura': 61, 'pequeno': 62, 'principalmente': 63, 'for': 64, 'maiores': 65, '60': 66, 'mais': 67, 'rodinhas': 68, 'giram': 69, 'macio': 70, 'veio': 71, 'riscada': 72, 'nada': 73, 'demais': 74, 'dif√≠cil': 75, 'sozinha': 76, 'hora': 77, 'encaixar': 78, 'os': 79, 'bra√ßos': 80, 'fora': 81, 'isso': 82, 'adorei': 83, 'compra': 84, 'sentar': 85, 'causa': 86, 'impress√£o': 87, 'te': 88, 'jogando': 89, 'frente': 90, 'eu': 91, 'quiser': 92, 'numa': 93, 'posi√ß√£o': 94, 'tenho': 95, 'exercendo': 96, 'contra': 97, 'conseguir': 98, 'ereto': 99, 'alavanca': 100, 'embaixo': 101, 'me': 102, 'enganou': 103, 'fosse': 104, 'regular': 105, 'ejetar': 106, 'da': 107, 'quem': 108, 'usava': 109, 'banquinho': 110, 'escrivaninha': 111, 'essa': 112, 'certeza': 113, 'foi': 114, 'upgrade': 115, 'infelizmente': 116, 'faixa': 117, 'h√°': 118, 'muitas': 119, 'op√ß√µes': 120, 'melhores': 121, 'esta': 122, '6': 123, 'meses': 124, 'uso': 125, 'terei': 126, 'comprar': 127, 'outra': 128, 'fr√°gil': 129, 'pessoa': 130, '80kg': 131, 'usando': 132, 'trabalhar': 133, 'home': 134, 'office': 135, 'duas': 136, 'ou': 137, 'tr√™s': 138, 'vezes': 139, 'semana': 140, 'tem': 141, 'como': 142, 'consertar': 143, 'pe√ßa': 144, 'sustenta': 145, 'por': 146, 'dentro': 147, 'tamb√©m': 148, 'gostei': 149, 'acabamento': 150, 'estofado': 151, 'legal': 152, 'quase': 153, 'sem': 154, 'espuma': 155, 'acredito': 156, 'durar√°': 157, 'grita': 158, 'fragilidade': 159, 'montagem': 160, 'pe√ßas': 161, 'precisam': 162, 'encaixadas': 163, 'certa': 164, 'ficarem': 165, 'perfeitas': 166, 'fresco': 167, 'detalhes': 168, 'das': 169, 'rodas': 170, 'branco': 171, 'diferente': 172, 'aparece': 173, 'nas': 174, 'fotos': 175, 'estranho': 176, 'qualidade': 177, 'proporcional': 178, 'ao': 179, 'ofertado': 180, 'aconselho': 181, 'altas': 182, '75': 183, 'pois': 184, 'desconfort√°vel': 185, 'ponto': 186, 'importante': 187, 'transportadora': 188, 'empresa': 189, 'realiza': 190, 'venda': 191, 'p√©ssima': 192, 'minha': 193, 'chegou': 194, 'extremamente': 195, 'danificada': 196, 'sendo': 197, 'dor': 198, 'cabe√ßa': 199, 'solicitar': 200, 'devolu√ß√£o': 201, 'otimo': 202, 'custo': 203, 'beneficio': 204}\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "frases = reviews\n",
    "\n",
    "tokenizer = Tokenizer(num_words=100)  # num_words igual a 100 significa 100 palavras mais relevantes\n",
    "tokenizer.fit_on_texts(frases)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "print(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_index {'<OOV>': 1, 'a': 2, '√©': 3, 'de': 4, 'n√£o': 5, 'para': 6, 'que': 7, 'o': 8, 'e': 9, 'cadeira': 10, 'do': 11, 'um': 12, 'assento': 13, 'boa': 14, 'se': 15, 'muito': 16, 'produto': 17, 'for√ßa': 18, 'em': 19, 'recomendo': 20, 'na': 21, 'ela': 22, 'ficar': 23, 'com': 24, 'uma': 25, 'apenas': 26, 'ser': 27, 'montar': 28, 'mas': 29, 'pouco': 30, 'bem': 31, 'torna': 32, 'pessoas': 33, '1': 34, 'altura': 35, 'no': 36, 'as': 37, 'base': 38, 'bom': 39, 'nessa': 40, 'est√°': 41, 'confort√°vel': 42, 'encosto': 43, 'achei': 44, 'pre√ßo': 45, 'quebrou': 46, 'm√≠dia': 47, 'p√¥de': 48, 'carregada': 49, 'dificil': 50, 'exige': 51, 'pra': 52, 'ajustar': 53, 'nos': 54, 'pinos': 55, 'encaixe': 56, 'encaixou': 57, 'minhas': 58, 'costas': 59, 'porem': 60, 'pela': 61, 'curvatura': 62, 'pequeno': 63, 'principalmente': 64, 'for': 65, 'maiores': 66, '60': 67, 'mais': 68, 'rodinhas': 69, 'giram': 70, 'macio': 71, 'veio': 72, 'riscada': 73, 'nada': 74, 'demais': 75, 'dif√≠cil': 76, 'sozinha': 77, 'hora': 78, 'encaixar': 79, 'os': 80, 'bra√ßos': 81, 'fora': 82, 'isso': 83, 'adorei': 84, 'compra': 85, 'sentar': 86, 'causa': 87, 'impress√£o': 88, 'te': 89, 'jogando': 90, 'frente': 91, 'eu': 92, 'quiser': 93, 'numa': 94, 'posi√ß√£o': 95, 'tenho': 96, 'exercendo': 97, 'contra': 98, 'conseguir': 99, 'ereto': 100, 'alavanca': 101, 'embaixo': 102, 'me': 103, 'enganou': 104, 'fosse': 105, 'regular': 106, 'ejetar': 107, 'da': 108, 'quem': 109, 'usava': 110, 'banquinho': 111, 'escrivaninha': 112, 'essa': 113, 'certeza': 114, 'foi': 115, 'upgrade': 116, 'infelizmente': 117, 'faixa': 118, 'h√°': 119, 'muitas': 120, 'op√ß√µes': 121, 'melhores': 122, 'esta': 123, '6': 124, 'meses': 125, 'uso': 126, 'terei': 127, 'comprar': 128, 'outra': 129, 'fr√°gil': 130, 'pessoa': 131, '80kg': 132, 'usando': 133, 'trabalhar': 134, 'home': 135, 'office': 136, 'duas': 137, 'ou': 138, 'tr√™s': 139, 'vezes': 140, 'semana': 141, 'tem': 142, 'como': 143, 'consertar': 144, 'pe√ßa': 145, 'sustenta': 146, 'por': 147, 'dentro': 148, 'tamb√©m': 149, 'gostei': 150, 'acabamento': 151, 'estofado': 152, 'legal': 153, 'quase': 154, 'sem': 155, 'espuma': 156, 'acredito': 157, 'durar√°': 158, 'grita': 159, 'fragilidade': 160, 'montagem': 161, 'pe√ßas': 162, 'precisam': 163, 'encaixadas': 164, 'certa': 165, 'ficarem': 166, 'perfeitas': 167, 'fresco': 168, 'detalhes': 169, 'das': 170, 'rodas': 171, 'branco': 172, 'diferente': 173, 'aparece': 174, 'nas': 175, 'fotos': 176, 'estranho': 177, 'qualidade': 178, 'proporcional': 179, 'ao': 180, 'ofertado': 181, 'aconselho': 182, 'altas': 183, '75': 184, 'pois': 185, 'desconfort√°vel': 186, 'ponto': 187, 'importante': 188, 'transportadora': 189, 'empresa': 190, 'realiza': 191, 'venda': 192, 'p√©ssima': 193, 'minha': 194, 'chegou': 195, 'extremamente': 196, 'danificada': 197, 'sendo': 198, 'dor': 199, 'cabe√ßa': 200, 'solicitar': 201, 'devolu√ß√£o': 202, 'otimo': 203, 'custo': 204, 'beneficio': 205}\n",
      "sequencias [[2, 47, 5, 48, 27, 49, 14, 5, 3, 50, 4, 28, 29, 51, 12, 30, 4, 18, 52, 53, 54, 55, 4, 56, 57, 31, 19, 58, 59, 60, 61, 62, 8, 13, 32, 15, 63, 64, 15, 65, 6, 33, 66, 4, 34, 67, 4, 35, 36, 68, 20, 3, 14, 37, 69, 70, 31, 9, 8, 13, 3, 71], [2, 38, 72, 12, 30, 73, 74, 75, 76, 28, 77, 21, 78, 4, 79, 80, 81, 36, 13, 82, 83, 84, 2, 85], [16, 14, 2, 10], [16, 14], [39, 8, 17, 20], [86, 40, 10, 87, 2, 88, 4, 7, 22, 41, 89, 90, 6, 91, 15, 92, 93, 23, 94, 95, 42, 24, 22, 96, 7, 23, 97, 25, 18, 98, 8, 43, 6, 99, 23, 1, 2, 1, 1, 1, 1, 44, 7, 1, 6, 1, 2, 35, 29, 3, 26, 6, 1, 8, 13, 1, 38, 6, 1, 1, 12, 1, 6, 2, 1, 1, 10, 24, 1, 1, 12, 1, 9, 1, 40, 1, 4, 45, 5, 1, 1, 1, 1, 11, 7, 1], [26, 1, 1, 4, 1, 9, 1, 7, 1, 1, 10, 2, 10, 3, 1, 26, 25, 1, 4, 1, 1, 6, 1, 19, 1, 1, 1, 1, 1, 1, 21, 1, 9, 22, 46, 9, 5, 1, 1, 1, 2, 1, 7, 1, 8, 13, 46, 1, 1, 2, 10, 1, 5, 3, 42], [5, 1, 11, 1, 11, 17, 8, 1, 5, 3, 1, 1, 1, 1, 9, 1, 7, 5, 1, 16, 1, 1, 21, 1, 37, 1, 1, 27, 1, 24, 1, 18, 6, 1, 1, 8, 43, 3, 39, 9, 1, 1, 1, 1, 19, 1, 1, 11, 7, 1, 1, 1, 44, 1, 5, 20], [2, 1, 11, 17, 3, 1, 1, 45, 1, 5, 1, 6, 33, 1, 34, 1, 1, 15, 32, 16, 1, 12, 1, 1, 3, 7, 2, 1, 7, 2, 1, 1, 2, 1, 11, 17, 3, 1, 1, 10, 1, 1, 1, 9, 41, 1, 25, 1, 4, 1, 1, 2, 1], [1, 1, 1]]\n",
      "sequencias_preenchidas [[ 2 47  5 48 27 49]\n",
      " [ 2 38 72 12 30 73]\n",
      " [16 14  2 10  0  0]\n",
      " [16 14  0  0  0  0]\n",
      " [39  8 17 20  0  0]\n",
      " [86 40 10 87  2 88]\n",
      " [26  1  1  4  1  9]\n",
      " [ 5  1 11  1 11 17]\n",
      " [ 2  1 11 17  3  1]\n",
      " [ 1  1  1  0  0  0]]\n",
      "testando_sequencias [[2, 47, 5, 48, 27, 49, 14, 5, 3, 50, 4, 28, 29, 51, 12, 30, 4, 18, 52, 53, 54, 55, 4, 56, 57, 31, 19, 58, 59, 60, 61, 62, 8, 13, 32, 15, 63, 64, 15, 65, 6, 33, 66, 4, 34, 67, 4, 35, 36, 68, 20, 3, 14, 37, 69, 70, 31, 9, 8, 13, 3, 71], [2, 38, 72, 12, 30, 73, 74, 75, 76, 28, 77, 21, 78, 4, 79, 80, 81, 36, 13, 82, 83, 84, 2, 85], [16, 14, 2, 10], [16, 14], [39, 8, 17, 20], [86, 40, 10, 87, 2, 88, 4, 7, 22, 41, 89, 90, 6, 91, 15, 92, 93, 23, 94, 95, 42, 24, 22, 96, 7, 23, 97, 25, 18, 98, 8, 43, 6, 99, 23, 1, 2, 1, 1, 1, 1, 44, 7, 1, 6, 1, 2, 35, 29, 3, 26, 6, 1, 8, 13, 1, 38, 6, 1, 1, 12, 1, 6, 2, 1, 1, 10, 24, 1, 1, 12, 1, 9, 1, 40, 1, 4, 45, 5, 1, 1, 1, 1, 11, 7, 1], [26, 1, 1, 4, 1, 9, 1, 7, 1, 1, 10, 2, 10, 3, 1, 26, 25, 1, 4, 1, 1, 6, 1, 19, 1, 1, 1, 1, 1, 1, 21, 1, 9, 22, 46, 9, 5, 1, 1, 1, 2, 1, 7, 1, 8, 13, 46, 1, 1, 2, 10, 1, 5, 3, 42], [5, 1, 11, 1, 11, 17, 8, 1, 5, 3, 1, 1, 1, 1, 9, 1, 7, 5, 1, 16, 1, 1, 21, 1, 37, 1, 1, 27, 1, 24, 1, 18, 6, 1, 1, 8, 43, 3, 39, 9, 1, 1, 1, 1, 19, 1, 1, 11, 7, 1, 1, 1, 44, 1, 5, 20], [2, 1, 11, 17, 3, 1, 1, 45, 1, 5, 1, 6, 33, 1, 34, 1, 1, 15, 32, 16, 1, 12, 1, 1, 3, 7, 2, 1, 7, 2, 1, 1, 2, 1, 11, 17, 3, 1, 1, 10, 1, 1, 1, 9, 41, 1, 25, 1, 4, 1, 1, 2, 1], [1, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "frases = base['content']\n",
    "\n",
    "#tokenizer = Tokenizer(num_words=100)  # num_words igual a 100 significa 100 palavras mais relevantes\n",
    "tokenizer = Tokenizer(num_words=100, oov_token=\"<OOV>\")  # oov = out of vocabulary\n",
    "tokenizer.fit_on_texts(frases)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "sequencias = tokenizer.texts_to_sequences(frases)\n",
    "\n",
    "sequencias_preenchidas = pad_sequences(sequencias, padding='post'\n",
    "                       , truncating='post', maxlen=6, value=0)  # pad = preencher  # truncate = cortar # pre ou post\n",
    "\n",
    "print(\"word_index\", word_index)\n",
    "print(\"sequencias\", sequencias)\n",
    "print(\"sequencias_preenchidas\", sequencias_preenchidas)\n",
    "\n",
    "testando = reviews\n",
    "\n",
    "testando_sequencias = tokenizer.texts_to_sequences(testando)\n",
    "print(\"testando_sequencias\", testando_sequencias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Etapa 1 - Carregar dados e organizar\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10800 entries, 0 to 10799\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   reviewId              10800 non-null  object\n",
      " 1   userName              10800 non-null  object\n",
      " 2   userImage             10800 non-null  object\n",
      " 3   content               10800 non-null  object\n",
      " 4   score                 10800 non-null  int64 \n",
      " 5   thumbsUpCount         10800 non-null  int64 \n",
      " 6   reviewCreatedVersion  9897 non-null   object\n",
      " 7   at                    10800 non-null  object\n",
      " 8   replyContent          2477 non-null   object\n",
      " 9   repliedAt             2477 non-null   object\n",
      " 10  sortOrder             10800 non-null  object\n",
      " 11  appId                 10800 non-null  object\n",
      "dtypes: int64(2), object(10)\n",
      "memory usage: 1012.6+ KB\n",
      "None\n",
      "                               reviewId            userName  \\\n",
      "0  d3f71fea-730b-4f94-b764-a7cf47d69f88    Priscila Gasques   \n",
      "1  f124c390-90c3-4153-9ca1-8e80c0f30a2c  Nathalia Dal Bello   \n",
      "2  7880950d-dd10-4d41-9d38-bfba1f7b0ddf         Alexssandra   \n",
      "3  1868a6f7-6087-4b5a-b564-87a58abc815d             Karol S   \n",
      "4  b674036c-fed4-4c4b-95c4-9c721f984a20       Amanda Mendes   \n",
      "\n",
      "                                           userImage  \\\n",
      "0  https://play-lh.googleusercontent.com/a-/ACB-R...   \n",
      "1  https://play-lh.googleusercontent.com/a-/ACB-R...   \n",
      "2  https://play-lh.googleusercontent.com/a-/ACB-R...   \n",
      "3  https://play-lh.googleusercontent.com/a-/ACB-R...   \n",
      "4  https://play-lh.googleusercontent.com/a-/ACB-R...   \n",
      "\n",
      "                                             content  score  thumbsUpCount  \\\n",
      "0  Aten√ß√£o o aplicativo j√° foi muito bom e √∫til m...      1            167   \n",
      "1  O aplicativo era √≥timo, os descontos eram √≥tim...      1           1775   \n",
      "2  Sempre adorei o Ifood. Mas desde a √∫ltima atua...      1            164   \n",
      "3  A nova atualiza√ß√£o est√° uma üí© ficou horr√≠vel, ...      1              3   \n",
      "4  O aplicativo tem diversos erros. No momento de...      1            111   \n",
      "\n",
      "  reviewCreatedVersion                   at replyContent repliedAt  \\\n",
      "0              9.195.2  2023-03-06 22:22:02          NaN       NaN   \n",
      "1              9.190.0  2023-01-23 20:52:04          NaN       NaN   \n",
      "2              9.195.2  2023-03-07 03:36:35          NaN       NaN   \n",
      "3              9.195.2  2023-03-11 00:41:32          NaN       NaN   \n",
      "4              9.195.1  2023-02-24 14:34:26          NaN       NaN   \n",
      "\n",
      "       sortOrder                  appId  \n",
      "0  most_relevant  br.com.brainweb.ifood  \n",
      "1  most_relevant  br.com.brainweb.ifood  \n",
      "2  most_relevant  br.com.brainweb.ifood  \n",
      "3  most_relevant  br.com.brainweb.ifood  \n",
      "4  most_relevant  br.com.brainweb.ifood  \n",
      "0    Aten√ß√£o o aplicativo j√° foi muito bom e √∫til m...\n",
      "1    O aplicativo era √≥timo, os descontos eram √≥tim...\n",
      "2    Sempre adorei o Ifood. Mas desde a √∫ltima atua...\n",
      "3    A nova atualiza√ß√£o est√° uma üí© ficou horr√≠vel, ...\n",
      "4    O aplicativo tem diversos erros. No momento de...\n",
      "Name: content, dtype: object\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: score, dtype: int64\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 7000 entries, 0 to 6999\n",
      "Series name: content\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "7000 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 54.8+ KB\n",
      "None\n",
      "0    Aten√ß√£o o aplicativo j√° foi muito bom e √∫til m...\n",
      "1    O aplicativo era √≥timo, os descontos eram √≥tim...\n",
      "2    Sempre adorei o Ifood. Mas desde a √∫ltima atua...\n",
      "3    A nova atualiza√ß√£o est√° uma üí© ficou horr√≠vel, ...\n",
      "4    O aplicativo tem diversos erros. No momento de...\n",
      "Name: content, dtype: object\n",
      "### Etapa 2 - Converter palavras em numeros\n",
      "### Etapa 3 - Criar as frases/sequencias\n",
      "### Etapa 4 - Criando a rede neural\n",
      "### Etapa 5 - Treinando a rede\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vitor\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 - 2s - 11ms/step - accuracy: 0.6594 - loss: 0.6258 - val_accuracy: 0.6918 - val_loss: 0.6003\n",
      "Epoch 2/30\n",
      "219/219 - 1s - 3ms/step - accuracy: 0.6747 - loss: 0.6111 - val_accuracy: 0.7000 - val_loss: 0.5858\n",
      "Epoch 3/30\n",
      "219/219 - 1s - 3ms/step - accuracy: 0.7087 - loss: 0.5830 - val_accuracy: 0.7224 - val_loss: 0.5493\n",
      "Epoch 4/30\n",
      "219/219 - 1s - 3ms/step - accuracy: 0.7447 - loss: 0.5298 - val_accuracy: 0.7229 - val_loss: 0.5496\n",
      "Epoch 5/30\n",
      "219/219 - 1s - 5ms/step - accuracy: 0.7727 - loss: 0.4833 - val_accuracy: 0.7479 - val_loss: 0.5375\n",
      "Epoch 6/30\n",
      "219/219 - 1s - 3ms/step - accuracy: 0.8041 - loss: 0.4470 - val_accuracy: 0.7513 - val_loss: 0.5587\n",
      "Epoch 7/30\n",
      "219/219 - 1s - 3ms/step - accuracy: 0.8213 - loss: 0.4160 - val_accuracy: 0.7474 - val_loss: 0.6086\n",
      "Epoch 8/30\n",
      "219/219 - 1s - 3ms/step - accuracy: 0.8354 - loss: 0.3822 - val_accuracy: 0.7550 - val_loss: 0.6466\n",
      "Epoch 9/30\n",
      "219/219 - 1s - 3ms/step - accuracy: 0.8513 - loss: 0.3563 - val_accuracy: 0.7482 - val_loss: 0.7283\n",
      "Epoch 10/30\n",
      "219/219 - 1s - 6ms/step - accuracy: 0.8621 - loss: 0.3307 - val_accuracy: 0.7439 - val_loss: 0.7881\n",
      "Epoch 11/30\n",
      "219/219 - 1s - 6ms/step - accuracy: 0.8714 - loss: 0.3138 - val_accuracy: 0.7405 - val_loss: 0.8673\n",
      "Epoch 12/30\n",
      "219/219 - 1s - 3ms/step - accuracy: 0.8737 - loss: 0.3038 - val_accuracy: 0.7266 - val_loss: 1.0238\n",
      "Epoch 13/30\n",
      "219/219 - 1s - 3ms/step - accuracy: 0.8876 - loss: 0.2796 - val_accuracy: 0.7413 - val_loss: 0.9914\n",
      "Epoch 14/30\n",
      "219/219 - 1s - 3ms/step - accuracy: 0.8927 - loss: 0.2683 - val_accuracy: 0.7384 - val_loss: 1.0532\n",
      "Epoch 15/30\n",
      "219/219 - 1s - 3ms/step - accuracy: 0.9006 - loss: 0.2537 - val_accuracy: 0.7371 - val_loss: 1.1622\n",
      "Epoch 16/30\n",
      "219/219 - 1s - 3ms/step - accuracy: 0.9090 - loss: 0.2385 - val_accuracy: 0.7387 - val_loss: 1.2244\n",
      "Epoch 17/30\n",
      "219/219 - 1s - 3ms/step - accuracy: 0.9141 - loss: 0.2201 - val_accuracy: 0.7382 - val_loss: 1.2864\n",
      "Epoch 18/30\n",
      "219/219 - 1s - 3ms/step - accuracy: 0.9177 - loss: 0.2122 - val_accuracy: 0.7334 - val_loss: 1.3354\n",
      "Epoch 19/30\n",
      "219/219 - 1s - 3ms/step - accuracy: 0.9123 - loss: 0.2147 - val_accuracy: 0.7250 - val_loss: 1.5619\n",
      "Epoch 20/30\n",
      "219/219 - 1s - 3ms/step - accuracy: 0.9217 - loss: 0.2001 - val_accuracy: 0.7311 - val_loss: 1.4828\n",
      "Epoch 21/30\n",
      "219/219 - 1s - 3ms/step - accuracy: 0.9276 - loss: 0.1936 - val_accuracy: 0.7350 - val_loss: 1.5920\n",
      "Epoch 22/30\n",
      "219/219 - 1s - 3ms/step - accuracy: 0.9241 - loss: 0.1927 - val_accuracy: 0.7332 - val_loss: 1.6438\n",
      "Epoch 23/30\n",
      "219/219 - 1s - 3ms/step - accuracy: 0.9374 - loss: 0.1727 - val_accuracy: 0.7245 - val_loss: 1.6492\n",
      "Epoch 24/30\n",
      "219/219 - 1s - 3ms/step - accuracy: 0.9351 - loss: 0.1671 - val_accuracy: 0.7205 - val_loss: 1.7029\n",
      "Epoch 25/30\n",
      "219/219 - 1s - 3ms/step - accuracy: 0.9394 - loss: 0.1618 - val_accuracy: 0.7339 - val_loss: 1.8556\n",
      "Epoch 26/30\n",
      "219/219 - 1s - 3ms/step - accuracy: 0.9449 - loss: 0.1510 - val_accuracy: 0.7305 - val_loss: 1.9276\n",
      "Epoch 27/30\n",
      "219/219 - 1s - 3ms/step - accuracy: 0.9427 - loss: 0.1496 - val_accuracy: 0.7300 - val_loss: 1.9962\n",
      "Epoch 28/30\n",
      "219/219 - 1s - 3ms/step - accuracy: 0.9487 - loss: 0.1431 - val_accuracy: 0.7300 - val_loss: 2.0891\n",
      "Epoch 29/30\n",
      "219/219 - 1s - 3ms/step - accuracy: 0.9470 - loss: 0.1415 - val_accuracy: 0.7271 - val_loss: 2.1090\n",
      "Epoch 30/30\n",
      "219/219 - 1s - 3ms/step - accuracy: 0.9447 - loss: 0.1441 - val_accuracy: 0.7250 - val_loss: 2.3292\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000\n",
    "embedding_dim = 16\n",
    "max_length = 100\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<OOV>\"\n",
    "\n",
    "print(\"### Etapa 1 - Carregar dados e organizar\")\n",
    "\n",
    "# carrega arquivo com as avaliacoes\n",
    "sentimento_df = pd.read_csv(\"reviews.csv\")\n",
    "\n",
    "print(sentimento_df.info())\n",
    "print(sentimento_df.head())\n",
    "print(sentimento_df['content'].head())\n",
    "print(sentimento_df['score'].head())\n",
    "\n",
    "# Converte notas de 1 a 5 em 0 e 1\n",
    "def to_sentiment(rating):\n",
    "  rating = int(rating)\n",
    "  if rating <= 2:\n",
    "    return 0\n",
    "  else:\n",
    "    return 1\n",
    "\n",
    "sentimento_df['sentiment'] = sentimento_df.score.apply(to_sentiment)\n",
    "\n",
    "# Organiza os dados em Treino e Teste\n",
    "training_size = 7000\n",
    "training_sentences = sentimento_df['content'].iloc[0:training_size].copy()\n",
    "testing_sentences = sentimento_df['content'].iloc[training_size:].copy()\n",
    "print(training_sentences.info())\n",
    "print(training_sentences.head())\n",
    "\n",
    "training_labels = sentimento_df['sentiment'].iloc[0:training_size].copy()\n",
    "testing_labels = sentimento_df['sentiment'].iloc[training_size:].copy()\n",
    "\n",
    "print(\"### Etapa 2 - Converter palavras em numeros\")\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "print(\"### Etapa 3 - Criar as frases/sequencias\")\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "sequencias_treinamento = tokenizer.texts_to_sequences(training_sentences)\n",
    "padded_treinamento = pad_sequences(sequencias_treinamento, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "sequencias_teste = tokenizer.texts_to_sequences(testing_sentences)\n",
    "padded_teste = pad_sequences(sequencias_teste, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "print(\"### Etapa 4 - Criando a rede neural\")\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "  tf.keras.layers.GlobalAveragePooling1D(),\n",
    "  tf.keras.layers.Dense(24, activation=\"relu\"),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(\"### Etapa 5 - Treinando a rede\")\n",
    "num_epochs = 30\n",
    "history = model.fit(padded_treinamento, training_labels, epochs=num_epochs,\n",
    "                    validation_data=(padded_teste, testing_labels), verbose=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Etapa 1 - Carregar dados e organizar\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10800 entries, 0 to 10799\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   reviewId              10800 non-null  object\n",
      " 1   userName              10800 non-null  object\n",
      " 2   userImage             10800 non-null  object\n",
      " 3   content               10800 non-null  object\n",
      " 4   score                 10800 non-null  int64 \n",
      " 5   thumbsUpCount         10800 non-null  int64 \n",
      " 6   reviewCreatedVersion  9897 non-null   object\n",
      " 7   at                    10800 non-null  object\n",
      " 8   replyContent          2477 non-null   object\n",
      " 9   repliedAt             2477 non-null   object\n",
      " 10  sortOrder             10800 non-null  object\n",
      " 11  appId                 10800 non-null  object\n",
      "dtypes: int64(2), object(10)\n",
      "memory usage: 1012.6+ KB\n",
      "None\n",
      "                               reviewId            userName  \\\n",
      "0  d3f71fea-730b-4f94-b764-a7cf47d69f88    Priscila Gasques   \n",
      "1  f124c390-90c3-4153-9ca1-8e80c0f30a2c  Nathalia Dal Bello   \n",
      "2  7880950d-dd10-4d41-9d38-bfba1f7b0ddf         Alexssandra   \n",
      "3  1868a6f7-6087-4b5a-b564-87a58abc815d             Karol S   \n",
      "4  b674036c-fed4-4c4b-95c4-9c721f984a20       Amanda Mendes   \n",
      "\n",
      "                                           userImage  \\\n",
      "0  https://play-lh.googleusercontent.com/a-/ACB-R...   \n",
      "1  https://play-lh.googleusercontent.com/a-/ACB-R...   \n",
      "2  https://play-lh.googleusercontent.com/a-/ACB-R...   \n",
      "3  https://play-lh.googleusercontent.com/a-/ACB-R...   \n",
      "4  https://play-lh.googleusercontent.com/a-/ACB-R...   \n",
      "\n",
      "                                             content  score  thumbsUpCount  \\\n",
      "0  Aten√ß√£o o aplicativo j√° foi muito bom e √∫til m...      1            167   \n",
      "1  O aplicativo era √≥timo, os descontos eram √≥tim...      1           1775   \n",
      "2  Sempre adorei o Ifood. Mas desde a √∫ltima atua...      1            164   \n",
      "3  A nova atualiza√ß√£o est√° uma üí© ficou horr√≠vel, ...      1              3   \n",
      "4  O aplicativo tem diversos erros. No momento de...      1            111   \n",
      "\n",
      "  reviewCreatedVersion                   at replyContent repliedAt  \\\n",
      "0              9.195.2  2023-03-06 22:22:02          NaN       NaN   \n",
      "1              9.190.0  2023-01-23 20:52:04          NaN       NaN   \n",
      "2              9.195.2  2023-03-07 03:36:35          NaN       NaN   \n",
      "3              9.195.2  2023-03-11 00:41:32          NaN       NaN   \n",
      "4              9.195.1  2023-02-24 14:34:26          NaN       NaN   \n",
      "\n",
      "       sortOrder                  appId  \n",
      "0  most_relevant  br.com.brainweb.ifood  \n",
      "1  most_relevant  br.com.brainweb.ifood  \n",
      "2  most_relevant  br.com.brainweb.ifood  \n",
      "3  most_relevant  br.com.brainweb.ifood  \n",
      "4  most_relevant  br.com.brainweb.ifood  \n",
      "0    Aten√ß√£o o aplicativo j√° foi muito bom e √∫til m...\n",
      "1    O aplicativo era √≥timo, os descontos eram √≥tim...\n",
      "2    Sempre adorei o Ifood. Mas desde a √∫ltima atua...\n",
      "3    A nova atualiza√ß√£o est√° uma üí© ficou horr√≠vel, ...\n",
      "4    O aplicativo tem diversos erros. No momento de...\n",
      "Name: content, dtype: object\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: score, dtype: int64\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 7000 entries, 0 to 6999\n",
      "Series name: content\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "7000 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 54.8+ KB\n",
      "None\n",
      "0    Aten√ß√£o o aplicativo j√° foi muito bom e √∫til m...\n",
      "1    O aplicativo era √≥timo, os descontos eram √≥tim...\n",
      "2    Sempre adorei o Ifood. Mas desde a √∫ltima atua...\n",
      "3    A nova atualiza√ß√£o est√° uma üí© ficou horr√≠vel, ...\n",
      "4    O aplicativo tem diversos erros. No momento de...\n",
      "Name: content, dtype: object\n",
      "### Etapa 2 - Converter palavras em n√∫meros\n",
      "### Etapa 3 - Criar as frases/sequ√™ncias\n",
      "### Etapa 4 - Criando a rede neural\n",
      "### Etapa 5 - Treinando a rede\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vitor\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 - 3s - 11ms/step - accuracy: 0.6851 - loss: 0.6238 - val_accuracy: 0.6316 - val_loss: 0.6307\n",
      "Epoch 2/30\n",
      "219/219 - 1s - 3ms/step - accuracy: 0.6956 - loss: 0.5762 - val_accuracy: 0.6355 - val_loss: 0.5926\n",
      "Epoch 3/30\n",
      "219/219 - 1s - 3ms/step - accuracy: 0.7113 - loss: 0.5532 - val_accuracy: 0.6576 - val_loss: 0.5679\n",
      "Epoch 4/30\n",
      "219/219 - 1s - 3ms/step - accuracy: 0.7391 - loss: 0.5147 - val_accuracy: 0.7403 - val_loss: 0.5351\n",
      "Epoch 5/30\n",
      "219/219 - 1s - 3ms/step - accuracy: 0.7680 - loss: 0.4782 - val_accuracy: 0.6874 - val_loss: 0.5266\n",
      "Epoch 6/30\n",
      "219/219 - 1s - 3ms/step - accuracy: 0.8034 - loss: 0.4354 - val_accuracy: 0.7568 - val_loss: 0.4949\n",
      "Epoch 7/30\n",
      "219/219 - 1s - 3ms/step - accuracy: 0.8080 - loss: 0.4127 - val_accuracy: 0.7647 - val_loss: 0.4866\n",
      "Epoch 8/30\n",
      "219/219 - 1s - 4ms/step - accuracy: 0.8343 - loss: 0.3809 - val_accuracy: 0.7050 - val_loss: 0.5392\n",
      "Epoch 9/30\n",
      "219/219 - 1s - 7ms/step - accuracy: 0.8419 - loss: 0.3604 - val_accuracy: 0.7700 - val_loss: 0.4838\n",
      "Epoch 10/30\n",
      "219/219 - 1s - 5ms/step - accuracy: 0.8434 - loss: 0.3505 - val_accuracy: 0.8042 - val_loss: 0.4712\n",
      "Epoch 11/30\n",
      "219/219 - 1s - 3ms/step - accuracy: 0.8653 - loss: 0.3194 - val_accuracy: 0.7468 - val_loss: 0.5143\n",
      "Epoch 12/30\n",
      "219/219 - 1s - 3ms/step - accuracy: 0.8750 - loss: 0.3041 - val_accuracy: 0.7968 - val_loss: 0.4804\n",
      "Epoch 13/30\n",
      "219/219 - 1s - 3ms/step - accuracy: 0.8841 - loss: 0.2837 - val_accuracy: 0.7524 - val_loss: 0.5376\n",
      "Epoch 14/30\n",
      "219/219 - 1s - 7ms/step - accuracy: 0.8766 - loss: 0.2885 - val_accuracy: 0.7568 - val_loss: 0.5377\n",
      "Epoch 15/30\n",
      "219/219 - 1s - 4ms/step - accuracy: 0.8907 - loss: 0.2633 - val_accuracy: 0.7963 - val_loss: 0.5015\n",
      "Epoch 16/30\n",
      "219/219 - 1s - 4ms/step - accuracy: 0.8957 - loss: 0.2604 - val_accuracy: 0.7939 - val_loss: 0.5087\n",
      "Epoch 17/30\n",
      "219/219 - 1s - 3ms/step - accuracy: 0.8934 - loss: 0.2525 - val_accuracy: 0.7884 - val_loss: 0.5232\n",
      "Epoch 18/30\n",
      "219/219 - 1s - 4ms/step - accuracy: 0.9034 - loss: 0.2294 - val_accuracy: 0.7803 - val_loss: 0.5399\n",
      "Epoch 19/30\n",
      "219/219 - 1s - 3ms/step - accuracy: 0.9083 - loss: 0.2253 - val_accuracy: 0.7832 - val_loss: 0.5484\n",
      "Epoch 20/30\n",
      "219/219 - 1s - 3ms/step - accuracy: 0.9183 - loss: 0.2089 - val_accuracy: 0.7871 - val_loss: 0.5537\n",
      "Epoch 21/30\n",
      "219/219 - 1s - 3ms/step - accuracy: 0.9170 - loss: 0.2008 - val_accuracy: 0.7900 - val_loss: 0.5659\n",
      "Epoch 22/30\n",
      "219/219 - 1s - 6ms/step - accuracy: 0.9200 - loss: 0.1993 - val_accuracy: 0.7358 - val_loss: 0.6722\n",
      "Epoch 23/30\n",
      "219/219 - 1s - 3ms/step - accuracy: 0.9133 - loss: 0.2077 - val_accuracy: 0.7350 - val_loss: 0.6789\n",
      "Epoch 24/30\n",
      "219/219 - 1s - 4ms/step - accuracy: 0.9199 - loss: 0.1966 - val_accuracy: 0.7839 - val_loss: 0.5964\n",
      "Epoch 25/30\n",
      "219/219 - 1s - 4ms/step - accuracy: 0.9244 - loss: 0.1856 - val_accuracy: 0.7582 - val_loss: 0.6610\n",
      "Epoch 26/30\n",
      "219/219 - 1s - 3ms/step - accuracy: 0.9371 - loss: 0.1702 - val_accuracy: 0.7779 - val_loss: 0.6228\n",
      "Epoch 27/30\n",
      "219/219 - 1s - 3ms/step - accuracy: 0.9333 - loss: 0.1699 - val_accuracy: 0.7737 - val_loss: 0.6391\n",
      "Epoch 28/30\n",
      "219/219 - 1s - 3ms/step - accuracy: 0.9384 - loss: 0.1627 - val_accuracy: 0.7692 - val_loss: 0.6864\n",
      "Epoch 29/30\n",
      "219/219 - 1s - 6ms/step - accuracy: 0.9284 - loss: 0.1813 - val_accuracy: 0.7526 - val_loss: 0.7190\n",
      "Epoch 30/30\n",
      "219/219 - 1s - 6ms/step - accuracy: 0.9240 - loss: 0.1754 - val_accuracy: 0.6984 - val_loss: 0.8456\n",
      "### Treinamento conclu√≠do\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Definindo hiperpar√¢metros\n",
    "vocab_size = 10000\n",
    "embedding_dim = 16\n",
    "max_length = 100\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok = \"<OOV>\"\n",
    "\n",
    "print(\"### Etapa 1 - Carregar dados e organizar\")\n",
    "\n",
    "# Carrega arquivo com as avalia√ß√µes\n",
    "sentimento_df = pd.read_csv(\"reviews.csv\")\n",
    "\n",
    "print(sentimento_df.info())\n",
    "print(sentimento_df.head())\n",
    "print(sentimento_df['content'].head())\n",
    "print(sentimento_df['score'].head())\n",
    "\n",
    "# Converte notas de 1 a 5 em 0 e 1\n",
    "def to_sentiment(rating):\n",
    "    rating = int(rating)\n",
    "    if rating <= 3:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "sentimento_df['sentiment'] = sentimento_df['score'].apply(to_sentiment)\n",
    "\n",
    "# Organiza os dados em Treino e Teste\n",
    "training_size = 7000\n",
    "training_sentences = sentimento_df['content'].iloc[0:training_size].copy()\n",
    "testing_sentences = sentimento_df['content'].iloc[training_size:].copy()\n",
    "print(training_sentences.info())\n",
    "print(training_sentences.head())\n",
    "\n",
    "training_labels = sentimento_df['sentiment'].iloc[0:training_size].copy()\n",
    "testing_labels = sentimento_df['sentiment'].iloc[training_size:].copy()\n",
    "\n",
    "print(\"### Etapa 2 - Converter palavras em n√∫meros\")\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "print(\"### Etapa 3 - Criar as frases/sequ√™ncias\")\n",
    "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "padded_training = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
    "padded_testing = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "print(\"### Etapa 4 - Criando a rede neural\")\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(24, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(\"### Etapa 5 - Treinando a rede\")\n",
    "num_epochs = 30\n",
    "history = model.fit(padded_training, training_labels, epochs=num_epochs,\n",
    "                    validation_data=(padded_testing, testing_labels), verbose=2)\n",
    "\n",
    "print(\"### Treinamento conclu√≠do\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Etapa 6 - Final - Testando com uma nova frase\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step\n",
      "Positivo: [0.97809577] A m√≠dia n√£o p√¥de ser carregada.\n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "Boa, N√£o √© dificil de montar, mas exige um pouco de for√ßa pra ajustar nos pinos de encaixe. Encaixou bem em minhas costas, porem pela curvatura o assento torna-se pequeno, principalmente se for para pessoas maiores de 1.60 de altura. No mais recomendo, √© boa, as rodinhas giram bem e o assento √© macio.\n",
      "Positivo: [0.94730884] A base veio um pouco riscada, nada demais. Dif√≠cil montar sozinha na hora de encaixar os bra√ßos no assento. Fora isso, adorei a compra\n",
      "Positivo: [0.9701521] Muito boa a cadeira.\n",
      "Positivo: [0.98585814] muito boa\n",
      "Positivo: [0.9838214] Bom o produto recomendo\n",
      "Negativo: [0.01977823] Sentar nessa cadeira causa a impress√£o de que ela est√° te jogando para frente. Se eu quiser ficar numa posi√ß√£o confort√°vel com ela, tenho que ficar exercendo uma for√ßa contra o encosto para conseguir ficar ereto.A alavanca embaixo me enganou. Achei que fosse para regular a altura mas √© apenas para ejetar o assento da base.Para quem usava um banquinho para a escrivaninha, essa cadeira com certeza foi um upgrade, e, infelizmente, nessa faixa de pre√ßo n√£o h√° muitas op√ß√µes melhores do que esta.\n",
      "Negativo: [0.15340807] Apenas 6 meses de uso e terei que comprar outra cadeira. A cadeira √© fr√°gil, apenas uma pessoa de 80kg usando, para trabalhar em home office duas ou tr√™s vezes na semana e ela quebrou e n√£o tem como consertar. A pe√ßa que sustenta o assento quebrou por dentro. A cadeira tamb√©m n√£o √© confort√°vel.\n",
      "Positivo: [0.99609333] N√£o gostei do acabamento do produto. O estofado n√£o √© legal, quase sem espuma e acredito que n√£o durar√° muito. Grita fragilidade. Na montagem as pe√ßas precisam ser encaixadas com certa for√ßa para ficarem perfeitas. O encosto √© bom e fresco. Detalhes das rodas em branco, diferente do que aparece nas fotos, achei estranho. N√£o recomendo.\n",
      "Negativo: [0.34662583] A qualidade do produto √© proporcional ao pre√ßo ofertado. N√£o aconselho para pessoas altas (+ 1,75) pois se torna muito desconfort√°vel. Um ponto importante √© que a transportadora que a empresa realiza a venda do produto √© p√©ssima. Minha cadeira chegou extremamente danificada e est√° sendo uma dor de cabe√ßa solicitar a devolu√ß√£o.\n",
      "Positivo: [0.9632537] Otimo custo beneficio\n"
     ]
    }
   ],
   "source": [
    "print(\"### Etapa 6 - Final - Testando com uma nova frase\")\n",
    "\n",
    "frases_avaliacao = reviews\n",
    "\n",
    "sequencia = tokenizer.texts_to_sequences(frases_avaliacao)\n",
    "padded = pad_sequences(sequencia, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "probs = model.predict(padded)\n",
    "\n",
    "class_names = ['Negativo:', 'Positivo:']\n",
    "for index, frase in enumerate(frases_avaliacao):\n",
    "  print(class_names[round(probs[index][0])], probs[index], frase)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
